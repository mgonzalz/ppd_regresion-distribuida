{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNCSQ/l9Wd3/XQxhIkXBXrv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgonzalz/ppd_regresion-distribuida/blob/main/regresion_distribuida.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Regresión con PySpark.**\n",
        "Mediante las técnicas de programación paralela y distribuida que ofrece PySpark, debemos de determinar el índice de Rendimiento Académico (*Performance Index*) que tienen los estudiantes atendiendo a una serie de variables.\n",
        "\n",
        "El dataset del que partimos tiene las siguientes variables independientes:\n",
        "\n",
        "* Hours Studied: El número total de horas que ha estudiado cada estudiante.\n",
        "* Previous Scores: Las notas que ha obtenido un estudiante en exámenes anteriores.\n",
        "* Extracurricular Activities: Si el estudiante participa en actividades extraescolares (Yes or No).\n",
        "* Sleep Hours: El número de horas que un estudiante duerme al día.\n",
        "* Sample Question Papers Practiced: El número de hojas de ejercicios que el estudiante realizó.\n",
        "Se trata de predecir el valor de la variable dependiente:\n",
        "\n",
        "* Performance Index: La medida del rendimiento académico de cada estudiante. Los valores están comprendidos entre 10 y 100, indicando los valores más altos un mayor rendimiento académico.\n",
        "\n",
        "Se valuará el modelo mediante **Root Mean Squared Error**."
      ],
      "metadata": {
        "id": "H30d9WtSP5vs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importaciones e instalación."
      ],
      "metadata": {
        "id": "94P9Ac-GQvuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evitar la subida de archivos manualmente en Google Colab, clonaremos directamente el repositorio donde se encuentran alojados estos archivos y luego los añadiremos al directorio actual.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yF-ttVwWFqz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mgonzalz/ppd_regresion-distribuida.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzfqYzp4DyLe",
        "outputId": "053366e7-7970-4a19-b765-87a30fa72805"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ppd_regresion-distribuida'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 14 (delta 2), reused 10 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (14/14), 49.46 KiB | 538.00 KiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ppd_regresion-distribuida/* ./ # Mover los archivos al directorio general"
      ],
      "metadata": {
        "id": "ICpAr7FJFHF1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ppd_regresion-distribuida # Eliminación de la carpeta vacía"
      ],
      "metadata": {
        "id": "X_OKprnwFPoM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El archivo `requirements.txt` contiene todas las versiones de los paquetes utilizados. A través de la siguiente secuencia de código los instalaremos e importaremos los métodos necesarios."
      ],
      "metadata": {
        "id": "Bpy-YAQySokc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjt1y5kfTDFU",
        "outputId": "e379d0d9-ea22-4dde-f75f-804d682fe8cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark==2.0.1 (from -r requirements.txt (line 1))\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting pyspark==3.5.1 (from -r requirements.txt (line 2))\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: IPython==7.34.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (7.34.0)\n",
            "Requirement already satisfied: jupyter_client==6.1.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.1.12)\n",
            "Requirement already satisfied: jupyter_core==5.7.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (5.7.2)\n",
            "Requirement already satisfied: notebook==6.5.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (6.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.5.1->-r requirements.txt (line 2)) (0.10.9.7)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython==7.34.0->-r requirements.txt (line 3)) (67.7.2)\n",
            "Collecting jedi>=0.16 (from IPython==7.34.0->-r requirements.txt (line 3))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython==7.34.0->-r requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython==7.34.0->-r requirements.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython==7.34.0->-r requirements.txt (line 3)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython==7.34.0->-r requirements.txt (line 3)) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython==7.34.0->-r requirements.txt (line 3)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython==7.34.0->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython==7.34.0->-r requirements.txt (line 3)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython==7.34.0->-r requirements.txt (line 3)) (4.9.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter_client==6.1.12->-r requirements.txt (line 4)) (23.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter_client==6.1.12->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter_client==6.1.12->-r requirements.txt (line 4)) (6.3.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter_core==5.7.2->-r requirements.txt (line 5)) (4.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (3.1.3)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (23.1.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (5.10.3)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (1.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (5.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->-r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython==7.34.0->-r requirements.txt (line 3)) (0.8.3)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->-r requirements.txt (line 6)) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->-r requirements.txt (line 6)) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (24.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->-r requirements.txt (line 6)) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->-r requirements.txt (line 6)) (4.19.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython==7.34.0->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython==7.34.0->-r requirements.txt (line 3)) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter_client==6.1.12->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook==6.5.5->-r requirements.txt (line 6)) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->-r requirements.txt (line 6)) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->-r requirements.txt (line 6)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->-r requirements.txt (line 6)) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->-r requirements.txt (line 6)) (0.18.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->-r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->-r requirements.txt (line 6)) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook==6.5.5->-r requirements.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->-r requirements.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->-r requirements.txt (line 6)) (2.21)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=f872618adddd1717a485c074846f0f996dbc3b9e01071763b35d5186a1d60447\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: findspark, pyspark, jedi\n",
            "Successfully installed findspark-2.0.1 jedi-0.19.1 pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python estándar\n",
        "import os\n",
        "import sys\n",
        "from typing import List\n",
        "\n",
        "# Configuración de Spark\n",
        "import findspark\n",
        "import pyspark\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Modelado y evaluación de Spark ML\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "metadata": {
        "id": "zR5Bf6LFQ7ek"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creación del entorno.\n",
        "\n",
        "Se preparará el entorno para el uso de Spark, descargando este y configurando las variables de entorno necesarias. Mediante `findspark` se habilitará la accesibilidad de Spark desde el entorno de ejecución. Finalmente, se crea la sesión de Spark."
      ],
      "metadata": {
        "id": "Z9Bdjo7YQDvl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "lSd-mcTuP3rR",
        "outputId": "e305661a-3275-4b02-d30c-3af45acc246b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [783 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,081 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,920 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,067 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,641 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,357 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,104 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [61.2 kB]\n",
            "Fetched 11.2 MB in 4s (3,127 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "58 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fd6aed2ae60>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://cd9e54c8974c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>regresion</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"regresion\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('regresion').getOrCreate()"
      ],
      "metadata": {
        "id": "kCVOUQ357g0A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estudio del rendimiento académico."
      ],
      "metadata": {
        "id": "k3Z0GB2V7UFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importación del dataset."
      ],
      "metadata": {
        "id": "rYokWsdH8Ytw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.read.csv(\"/content/data/Student_Performance.csv\", header=True, inferSchema=True)\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr6OL0lK7Z7I",
        "outputId": "b2e2971a-3f52-440c-b96d-1a6dab26a8fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+--------------------------+-----------+--------------------------------+-----------------+\n",
            "|Hours Studied|Previous Scores|Extracurricular Activities|Sleep Hours|Sample Question Papers Practiced|Performance Index|\n",
            "+-------------+---------------+--------------------------+-----------+--------------------------------+-----------------+\n",
            "|            7|             99|                       Yes|          9|                               1|             91.0|\n",
            "|            4|             82|                        No|          4|                               2|             65.0|\n",
            "|            8|             51|                       Yes|          7|                               2|             45.0|\n",
            "|            5|             52|                       Yes|          5|                               2|             36.0|\n",
            "|            7|             75|                        No|          8|                               5|             66.0|\n",
            "+-------------+---------------+--------------------------+-----------+--------------------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparación del dataset.\n",
        "Antes del ánalisis de datos, debemos de preparar los datos y tener un conocimiento sobre estos."
      ],
      "metadata": {
        "id": "-_IluoGG8g0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.toPandas().isnull().sum() # Valores nulos."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyxmkmjT_jQH",
        "outputId": "d376527d-b51a-4fc8-9cf1-00a7637ac62a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Hours Studied                       0\n",
              "Previous Scores                     0\n",
              "Extracurricular Activities          0\n",
              "Sleep Hours                         0\n",
              "Sample Question Papers Practiced    0\n",
              "Performance Index                   0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fkt07kT9CpI",
        "outputId": "8eae4600-6d0d-450d-8dde-7c4aed36e5dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Hours Studied: integer (nullable = true)\n",
            " |-- Previous Scores: integer (nullable = true)\n",
            " |-- Extracurricular Activities: string (nullable = true)\n",
            " |-- Sleep Hours: integer (nullable = true)\n",
            " |-- Sample Question Papers Practiced: integer (nullable = true)\n",
            " |-- Performance Index: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5L98uWS8PKn",
        "outputId": "2a5d36ef-a365-4e2f-8268-08913c5cd3c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hours Studied', 'int'),\n",
              " ('Previous Scores', 'int'),\n",
              " ('Extracurricular Activities', 'string'),\n",
              " ('Sleep Hours', 'int'),\n",
              " ('Sample Question Papers Practiced', 'int'),\n",
              " ('Performance Index', 'double')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Miramos la existencia de variables categóricas. Observamos que solo la columna `Extracurricular Activities` contiene de estos y realizaremos la codificación ordinal o *Label Encoding* de estos valores para poder realizar un análisis.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_1buqq7CMj4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.select('Extracurricular Activities').distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBTqllAcNNQc",
        "outputId": "52e94de3-78d5-4f32-dd7c-11b05c4fd1b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|Extracurricular Activities|\n",
            "+--------------------------+\n",
            "|                        No|\n",
            "|                       Yes|\n",
            "+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso al solo haber dos valores se puede hacer la codificación de manera manual."
      ],
      "metadata": {
        "id": "FYKW5mpGN0j0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.withColumn('Extracurricular Activities', F.when(data[\"Extracurricular Activities\"] == \"Yes\", 1).otherwise(0))"
      ],
      "metadata": {
        "id": "k78L7lEF-1t4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUmsFg0__LnK",
        "outputId": "406ba382-a59e-470a-8cd1-23e2092411f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+--------------------------+-----------+--------------------------------+-----------------+\n",
            "|Hours Studied|Previous Scores|Extracurricular Activities|Sleep Hours|Sample Question Papers Practiced|Performance Index|\n",
            "+-------------+---------------+--------------------------+-----------+--------------------------------+-----------------+\n",
            "|            7|             99|                         1|          9|                               1|             91.0|\n",
            "|            4|             82|                         0|          4|                               2|             65.0|\n",
            "|            8|             51|                         1|          7|                               2|             45.0|\n",
            "|            5|             52|                         1|          5|                               2|             36.0|\n",
            "|            7|             75|                         0|          8|                               5|             66.0|\n",
            "+-------------+---------------+--------------------------+-----------+--------------------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consideramos que el dataset ya esta preparado."
      ],
      "metadata": {
        "id": "UCFfY7a9OjIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión lineal."
      ],
      "metadata": {
        "id": "0wyMFT9d_yFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [col for col in data.columns if col != 'Performance Index'] #identificación variables independientes"
      ],
      "metadata": {
        "id": "lLSfka-B_5IX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols= feature_cols,\n",
        "    outputCol=\"features\")\n",
        "\n",
        "data = assembler.transform(data)\n",
        "final_data = data.select(\"features\", \"Performance Index\")\n",
        "\n",
        "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=53)"
      ],
      "metadata": {
        "id": "zeke8tTLAIAv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Performance Index\", predictionCol=\"y_pred\")\n",
        "lr_model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "7-_iSbiRAXt_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación del modelo."
      ],
      "metadata": {
        "id": "i_RHCxr5HU0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"Performance Index\", predictionCol=\"y_pred\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data: {:.3f}\".format(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJEQdf_NAio_",
        "outputId": "a4d7ca39-4445-4c72-9f07-dd637e39d336"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data: 2.068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5UwJWFuRBrT",
        "outputId": "4750bff2-1d47-4c95-83b6-7038259fa51e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+------------------+\n",
            "|            features|Performance Index|            y_pred|\n",
            "+--------------------+-----------------+------------------+\n",
            "|[1.0,40.0,0.0,4.0...|             15.0|11.993651539290596|\n",
            "|[1.0,40.0,0.0,5.0...|             10.0| 13.64685396290519|\n",
            "|[1.0,40.0,0.0,9.0...|             11.0|14.182652422722384|\n",
            "|[1.0,40.0,1.0,7.0...|             12.0|14.618491772149618|\n",
            "|[1.0,41.0,0.0,5.0...|             14.0|12.901483761986846|\n",
            "|[1.0,41.0,1.0,8.0...|             13.0|14.938226133428984|\n",
            "|[1.0,42.0,1.0,5.0...|             15.0|15.506292516780334|\n",
            "|[1.0,42.0,1.0,9.0...|             17.0|  17.8063845608482|\n",
            "|[1.0,42.0,1.0,9.0...|             18.0| 18.19844980179279|\n",
            "|[1.0,43.0,0.0,6.0...|             16.0|16.200467711321494|\n",
            "|[1.0,43.0,0.0,6.0...|             17.0|17.180630813682974|\n",
            "|[1.0,43.0,0.0,6.0...|             18.0|17.180630813682974|\n",
            "|[1.0,43.0,0.0,8.0...|             16.0| 16.95844849241083|\n",
            "|[1.0,43.0,0.0,9.0...|             18.0|17.043389952247054|\n",
            "|[1.0,44.0,0.0,5.0...|             17.0|16.938417014345283|\n",
            "|[1.0,44.0,0.0,8.0...|             21.0|18.957534978104626|\n",
            "|[1.0,45.0,1.0,6.0...|             18.0| 19.04006936755811|\n",
            "|[1.0,45.0,1.0,6.0...|             19.0|19.824199849447297|\n",
            "|[1.0,45.0,1.0,8.0...|             19.0| 19.40598490770285|\n",
            "|[1.0,46.0,0.0,4.0...|             20.0|18.891322321173703|\n",
            "+--------------------+-----------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}